{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_97oZUimESt"
      },
      "source": [
        "# Run your second classifier with Python: a Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26m2Y_UMmES6"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9kDKF9oZmES8",
        "outputId": "2e7e7c91-c22d-4aac-b343-9ee67de21b70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timespreg</th>\n",
              "      <th>gluctol</th>\n",
              "      <th>diaspb</th>\n",
              "      <th>triceps</th>\n",
              "      <th>insulin</th>\n",
              "      <th>massindex</th>\n",
              "      <th>pedigree</th>\n",
              "      <th>age</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     timespreg  gluctol  diaspb  triceps  insulin  massindex  pedigree  age  \\\n",
              "0            6      148      72       35        0       33.6     0.627   50   \n",
              "1            1       85      66       29        0       26.6     0.351   31   \n",
              "2            8      183      64        0        0       23.3     0.672   32   \n",
              "3            1       89      66       23       94       28.1     0.167   21   \n",
              "4            0      137      40       35      168       43.1     2.288   33   \n",
              "..         ...      ...     ...      ...      ...        ...       ...  ...   \n",
              "763         10      101      76       48      180       32.9     0.171   63   \n",
              "764          2      122      70       27        0       36.8     0.340   27   \n",
              "765          5      121      72       23      112       26.2     0.245   30   \n",
              "766          1      126      60        0        0       30.1     0.349   47   \n",
              "767          1       93      70       31        0       30.4     0.315   23   \n",
              "\n",
              "     target  \n",
              "0         1  \n",
              "1         0  \n",
              "2         1  \n",
              "3         0  \n",
              "4         1  \n",
              "..      ...  \n",
              "763       0  \n",
              "764       0  \n",
              "765       0  \n",
              "766       1  \n",
              "767       0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#import the dataset\n",
        "df = pd.read_csv('./data/diabetes.txt')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FQb7c1k7mETB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "dfnp = df.to_numpy()\n",
        "x=dfnp[:,0:-1] # prendiamo tutti i dati tranne l'ultima colonna -> variabili indipendenti, osservazioni\n",
        "y=dfnp[:,-1] # prendiamo solo l'ultima colonna -> variabile dipendente, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXBD_lHImETC"
      },
      "source": [
        "# split data into training/test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0BLDJZXOmETD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, \n",
        "                                                    test_size =0.33, #by default is 75%-25%\n",
        "                                                    #shuffle is set True by default,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state= 123) #fix random seed for replicability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6AWIL9AtmETF",
        "outputId": "38a2140b-aa65-433d-90e9-41e105be0e00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((514, 8), (514,), (254, 8), (254,))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmRdWuESmETH"
      },
      "source": [
        "# Train the classifier"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7c7wnFY7mETI"
      },
      "source": [
        "![img](https://drive.google.com/uc?export=view&id=1BVNr55ihoPr8EGcnFYz7xQoHcdVT99i_)\n",
        "![img](https://drive.google.com/uc?export=view&id=1lWO8TWy-Ec62ETJ9lzmnFNlrT2X73wfy)\n",
        "\n",
        "\n",
        "\n",
        "Questa volta proviamo a classificare i nostri diabetici utilizzando un altro metodo, cioè un altro classificatore: il decision tree. Possiamo vedere come funziona questo classificatore dando un occhio alla figura a fianco. In questo semplice esempio, vogliamo classificare un oggetto, la nostra variabile dipendente _y_, per stabilire (classificare) se è un cerchio o un quadrato. Per fare questo, il classificatore controlla il valore delle due variabili indipendenti _x_: se $$x_1 > w_{10}$$ e $$x_2 > w_{20}$$ allora è un quadrato, altrimenti è un cerchio.\n",
        "Visto così potrebbe sembrare un semplice programma che fa un paio di if. In realtà il metodo deve cercare di trovare i valori delle variabili indipendenti che meglio separano (cioè classificano) il nostro insieme in modo da dover fare meno passaggi possibili ed avere il massimo della correttezza. Potremmo avere infatti situazioni ben più complesse, come nell'esempio a fianco preso da un caso di frodi bancarie. Come vediamo si tratta di classificare molti casi diversi e ongi volta che effettuiamo una scelta, l'insieme si riduce fino ad arrivare ai singoli elementi. Notare che non sempre le classificazioni sono completamente corrette: nell'insieme d3 abbiamo anche qualche cerchio mentre nell'insieme d2 abbiamo un triangolo. Questo ci induce a pensare che il metodo nonriesca a classificare sempre tutti gli elementi in modo corretto e che anche qui, quindi, dovremo parlare di indicatori per valutare la sua bontà.\n",
        "\n",
        "__Ma da quali variabili indipendenti parte il metodo del decision tree per iniziare (e poi continuare) a suddividere i vari elementi in classi?__ Ci sono diverse criteri: noi utilizzeremo il Gini Index (introdotto dallo statistico italiano Corrado Gini per misurare la disuguaglianza in una distribuzione). Il coefficiente di Gini è un numero compreso tra 0 ed 1 ed è spesso usato per valutare se la ricchezza di un paese è distribuita equamente o no. Valori bassi del coefficiente indicano una distribuzione abbastanza omogenea, con il valore 0 che corrisponde alla pura equidistribuzione, ad esempio la situazione in cui tutti percepiscono esattamente lo stesso reddito; valori alti del coefficiente indicano una distribuzione più diseguale, con il valore 1 che corrisponde alla massima concentrazione, ovvero la situazione dove una persona percepisca tutto il reddito del paese mentre tutti gli altri hanno un reddito nullo.\n",
        "Nel caso del decision tree siamo interessati a trovare i valori di una certa variabile indipendente capaci di suddividere gli elementi in classi il più possibili omogenee, cioè con tutti i valori uguali, in modo da dover fare meno suddivisioni ed avere un albero con meno livelli: questo corrisponde a scegliere una variabile che permetta di avere un indice di Gini basso.\n",
        "\n",
        "Altra domanda: __quando ci dobbiamo fermare nella suddivisione (split) di un gruppo in sottogruppi?__ O, in altre parole, quanti livelli deve avere un albero? La risposta potrebbe essere quella di andare avanti ad effettuare le suddivisioni fino a quando non raggiungiamo dei sottoinsiemi finali (foglie) contenenti un solo elemento. Così facendo però il metodo soffrirebbe di __overfitting__, cioè sarebbe troppo ben \"allenato\" su un certo set di dati da non riuscire a fare poi previsioni corrette su altri set di dati.\n",
        "\n",
        "Vediamo ora di applicare il decision tree al caso dei diabetici. Noteremo che il procedimento sarà lo stesso di quello già visto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g3is4XgxmETM",
        "outputId": "2603a26c-a77d-4b9b-b612-d085261341a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dati predetti dal metodo =                [0. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
            "dati reali presenti nel dataset di test = [1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "# importiamo il metodo che vogliamo utilizzara (tra i tanti disponibili...)\n",
        "from sklearn import tree\n",
        "\n",
        "# impostiamo i parametri del metodo\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "tree_clf = tree.DecisionTreeClassifier(criterion=\"gini\", # criteri per stabilire come splittare\n",
        "                                       max_depth=4, # profondità dell'albero per evitare l'overfitting\n",
        "                                       min_samples_split=30, # dimensione minima del sottogruppo a cui fermarsi (no more split)\n",
        "                                       max_leaf_nodes=6, # numero dei nodi foglia\n",
        "                                       min_samples_leaf=4 # numero di campioni per essere una foglia\n",
        "                                      )\n",
        "\n",
        "# prima parte: dobbiamo fare in modo che il metodo impari dalle informazioni a disposizione\n",
        "tree_clf.fit(X_train,y_train)\n",
        "\n",
        "# seconda parte: vediamo se il metodo ha imparato bene facendogli prevedere i risultati \n",
        "predict = tree_clf.predict(X_test)\n",
        "\n",
        "# visualizziamo il risultato (solo i primi dieci pazienti)\n",
        "print(f'dati predetti dal metodo =                {predict[:10]}') # dati predetti dal metodo\n",
        "print(f'dati reali presenti nel dataset di test = {y_test[:10]}') # dati effettivi presenti nel test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLXBx7TrmETO"
      },
      "source": [
        "# Evaluate the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eJr8tsMmETP"
      },
      "source": [
        "Per valutare il nostro metodo, come abbiamo fatto anche per il K-NN visualizziamo la  \"confusion matrix\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LxBQmPmemETQ",
        "outputId": "bdb4d738-d1f0-4025-a857-d3d810518c4f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plots IMPORTS\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(y_test, predict))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqQOxZp6mETR"
      },
      "source": [
        "Questo metodo è meglio o peggio del K-NN nella classificazione dei diabetici? Confrontiamo le due confusion matrix (a sinistra quella relativa al metodo K-NN a destra quella relativa al metodo del decision tree):\n",
        "\n",
        "<img src=\"https://drive.google.com/file/d/1p3vrnHthr-Uu71kFkG24Z5U4PZ3VmgKa\" width=\"600\" align=\"left\"><img src=\"Images/cm decision tree.png\" width=\"350\" align=\"right\">\n",
        "\n",
        "Cosa possiamo dire?\n",
        "\n",
        "Visualizziamo anche i report con _accuracy, precision, recall_ ed _f1-score_ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HXOgJpRLmETR",
        "outputId": "eefeb9ac-9eb0-4165-c777-e65e9a21b127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.78      0.80       165\n",
            "         1.0       0.63      0.71      0.67        89\n",
            "\n",
            "    accuracy                           0.75       254\n",
            "   macro avg       0.73      0.74      0.73       254\n",
            "weighted avg       0.76      0.75      0.75       254\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubAKVS2umETS"
      },
      "source": [
        "Confrontiamolo con il report del K-NN (a sinistra K-NN, a destra decision tree):\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1p3vrnHthr-Uu71kFkG24Z5U4PZ3VmgKa\" width=\"410\" align=\"left\"><img src=\"https://drive.google.com/uc?export=view&id=1Is_R1IkAjiQpFZNlzlqBl6Q_t_5P0Ngt\" width=\"450\">\n",
        "\n",
        "Quale metodo è il migliore per il nostro caso di studio?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR64AHArmETT"
      },
      "source": [
        "Proviamo ora a fare la previsione per la nostra solita signora Maria:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9AgzuUnCmETU",
        "outputId": "c0b0a014-de5c-46ed-d5e6-416557705295"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# previsione per Maria\n",
        "Maria = [[10., 68., 106., 23., 49., 35.5, 0.285, 47.]]\n",
        "predictMaria = tree_clf.predict(Maria)\n",
        "predictMaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQul3imBmETV"
      },
      "source": [
        "La risposta è 0, cioà anche con questo metodo prevediamo che Maria non abbia il diabete. Ma vediamo ora che cosa sarebbe successo se Maria avesse un indice relativo all'insulina di 159 invece che 49:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hyBDYDwImETW",
        "outputId": "2c6dde0e-70e5-4efb-f6f5-09f336ff3423"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# nuova previsione per Maria\n",
        "Maria = [[10., 68., 106., 23., 159., 35.5, 0.285, 47.]]\n",
        "predictMaria = tree_clf.predict(Maria)\n",
        "predictMaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq8vSNuNmETX"
      },
      "source": [
        "La risposta è ancora 0, cioè il metodo dice che Maria, con questi nuovi valori, non avrebbe comunque il diabete. Notare che l'altro metodo (K-NN) ci aveva detto invece che Maria, con questi valori, avrebbe avuto il diabete.\n",
        "\n",
        "Questo fatto ci fa capire quanto sia importante, nel Machine Learning, il \"fattore umano\", cioè la capacità del data analyst di utilizzare in modo appropriato i metodi che le varie librerie mettono a disposizione. \n",
        "\n",
        "Come ultimo aspetto della nostra trattazione, visualizziamo l'abero che è stato generato dal metodo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h0sHRebImETa",
        "outputId": "606c6d9f-2b15-42d8-814f-d4361e90005a"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"533pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 533.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-548 529,-548 529,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f3c4a3\" stroke=\"black\" d=\"M317.5,-544C317.5,-544 211.5,-544 211.5,-544 205.5,-544 199.5,-538 199.5,-532 199.5,-532 199.5,-473 199.5,-473 199.5,-467 205.5,-461 211.5,-461 211.5,-461 317.5,-461 317.5,-461 323.5,-461 329.5,-467 329.5,-473 329.5,-473 329.5,-532 329.5,-532 329.5,-538 323.5,-544 317.5,-544\"/>\n<text text-anchor=\"start\" x=\"217.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gluctol ≤ 139.5</text>\n<text text-anchor=\"start\" x=\"227\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.454</text>\n<text text-anchor=\"start\" x=\"217\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 514</text>\n<text text-anchor=\"start\" x=\"207.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [335, 179]</text>\n<text text-anchor=\"start\" x=\"235.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#eda572\" stroke=\"black\" d=\"M244,-425C244,-425 131,-425 131,-425 125,-425 119,-419 119,-413 119,-413 119,-354 119,-354 119,-348 125,-342 131,-342 131,-342 244,-342 244,-342 250,-342 256,-348 256,-354 256,-354 256,-413 256,-413 256,-419 250,-425 244,-425\"/>\n<text text-anchor=\"start\" x=\"127\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">massindex ≤ 27.35</text>\n<text text-anchor=\"start\" x=\"150\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.348</text>\n<text text-anchor=\"start\" x=\"140\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 383</text>\n<text text-anchor=\"start\" x=\"134.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [297, 86]</text>\n<text text-anchor=\"start\" x=\"158.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M237.57,-460.58C232.09,-452.25 226.26,-443.39 220.59,-434.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"223.54,-432.89 215.12,-426.46 217.69,-436.74 223.54,-432.89\"/>\n<text text-anchor=\"middle\" x=\"209.24\" y=\"-445.99\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node9\" class=\"node\">\n<title>2</title>\n<path fill=\"#8ac5f0\" stroke=\"black\" d=\"M399,-425C399,-425 286,-425 286,-425 280,-425 274,-419 274,-413 274,-413 274,-354 274,-354 274,-348 280,-342 286,-342 286,-342 399,-342 399,-342 405,-342 411,-348 411,-354 411,-354 411,-413 411,-413 411,-419 405,-425 399,-425\"/>\n<text text-anchor=\"start\" x=\"282\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">massindex ≤ 29.85</text>\n<text text-anchor=\"start\" x=\"305\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.412</text>\n<text text-anchor=\"start\" x=\"295\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 131</text>\n<text text-anchor=\"start\" x=\"294\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [38, 93]</text>\n<text text-anchor=\"start\" x=\"313.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M291.78,-460.58C297.39,-452.16 303.36,-443.2 309.16,-434.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"311.89,-436.72 314.53,-426.46 306.07,-432.84 311.89,-436.72\"/>\n<text text-anchor=\"middle\" x=\"320.27\" y=\"-446.01\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node3\" class=\"node\">\n<title>3</title>\n<path fill=\"#e68844\" stroke=\"black\" d=\"M101,-298.5C101,-298.5 12,-298.5 12,-298.5 6,-298.5 0,-292.5 0,-286.5 0,-286.5 0,-242.5 0,-242.5 0,-236.5 6,-230.5 12,-230.5 12,-230.5 101,-230.5 101,-230.5 107,-230.5 113,-236.5 113,-242.5 113,-242.5 113,-286.5 113,-286.5 113,-292.5 107,-298.5 101,-298.5\"/>\n<text text-anchor=\"start\" x=\"19\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.098</text>\n<text text-anchor=\"start\" x=\"9\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 116</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [110, 6]</text>\n<text text-anchor=\"start\" x=\"27.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M141.68,-341.58C128.85,-330.12 114.91,-317.67 102.09,-306.22\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"104.77,-303.92 94.98,-299.87 100.11,-309.14 104.77,-303.92\"/>\n</g>\n<!-- 4 -->\n<g id=\"node4\" class=\"node\">\n<title>4</title>\n<path fill=\"#f0b78e\" stroke=\"black\" d=\"M241.5,-306C241.5,-306 143.5,-306 143.5,-306 137.5,-306 131.5,-300 131.5,-294 131.5,-294 131.5,-235 131.5,-235 131.5,-229 137.5,-223 143.5,-223 143.5,-223 241.5,-223 241.5,-223 247.5,-223 253.5,-229 253.5,-235 253.5,-235 253.5,-294 253.5,-294 253.5,-300 247.5,-306 241.5,-306\"/>\n<text text-anchor=\"start\" x=\"145.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gluctol ≤ 103.5</text>\n<text text-anchor=\"start\" x=\"159\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.42</text>\n<text text-anchor=\"start\" x=\"145\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 267</text>\n<text text-anchor=\"start\" x=\"139.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [187, 80]</text>\n<text text-anchor=\"start\" x=\"163.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;4 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M189.25,-341.58C189.58,-333.79 189.93,-325.53 190.28,-317.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"193.77,-317.85 190.7,-307.71 186.77,-317.55 193.77,-317.85\"/>\n</g>\n<!-- 5 -->\n<g id=\"node5\" class=\"node\">\n<title>5</title>\n<path fill=\"#ea985c\" stroke=\"black\" d=\"M172,-179.5C172,-179.5 83,-179.5 83,-179.5 77,-179.5 71,-173.5 71,-167.5 71,-167.5 71,-123.5 71,-123.5 71,-117.5 77,-111.5 83,-111.5 83,-111.5 172,-111.5 172,-111.5 178,-111.5 184,-117.5 184,-123.5 184,-123.5 184,-167.5 184,-167.5 184,-173.5 178,-179.5 172,-179.5\"/>\n<text text-anchor=\"start\" x=\"90\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.257</text>\n<text text-anchor=\"start\" x=\"80\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 112</text>\n<text text-anchor=\"start\" x=\"79\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [95, 17]</text>\n<text text-anchor=\"start\" x=\"98.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M169.77,-222.58C163.88,-211.99 157.53,-200.56 151.58,-189.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"154.69,-188.23 146.77,-181.18 148.57,-191.63 154.69,-188.23\"/>\n</g>\n<!-- 6 -->\n<g id=\"node6\" class=\"node\">\n<title>6</title>\n<path fill=\"#f7d7c1\" stroke=\"black\" d=\"M303,-187C303,-187 214,-187 214,-187 208,-187 202,-181 202,-175 202,-175 202,-116 202,-116 202,-110 208,-104 214,-104 214,-104 303,-104 303,-104 309,-104 315,-110 315,-116 315,-116 315,-175 315,-175 315,-181 309,-187 303,-187\"/>\n<text text-anchor=\"start\" x=\"224.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">age ≤ 28.5</text>\n<text text-anchor=\"start\" x=\"221\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.482</text>\n<text text-anchor=\"start\" x=\"211\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 155</text>\n<text text-anchor=\"start\" x=\"210\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [92, 63]</text>\n<text text-anchor=\"start\" x=\"229.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M215.58,-222.58C220.23,-214.34 225.17,-205.58 229.98,-197.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"232.93,-198.95 234.8,-188.52 226.84,-195.51 232.93,-198.95\"/>\n</g>\n<!-- 9 -->\n<g id=\"node7\" class=\"node\">\n<title>9</title>\n<path fill=\"#eeaf81\" stroke=\"black\" d=\"M238,-68C238,-68 149,-68 149,-68 143,-68 137,-62 137,-56 137,-56 137,-12 137,-12 137,-6 143,0 149,0 149,0 238,0 238,0 244,0 250,-6 250,-12 250,-12 250,-56 250,-56 250,-62 244,-68 238,-68\"/>\n<text text-anchor=\"start\" x=\"156\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.391</text>\n<text text-anchor=\"start\" x=\"150\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 75</text>\n<text text-anchor=\"start\" x=\"145\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 20]</text>\n<text text-anchor=\"start\" x=\"164.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 6&#45;&gt;9 -->\n<g id=\"edge6\" class=\"edge\">\n<title>6&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M234.3,-103.73C229.32,-95.34 224.06,-86.47 219.03,-78.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"222.15,-76.41 214.04,-69.6 216.13,-79.99 222.15,-76.41\"/>\n</g>\n<!-- 10 -->\n<g id=\"node8\" class=\"node\">\n<title>10</title>\n<path fill=\"#e3f1fb\" stroke=\"black\" d=\"M369,-68C369,-68 280,-68 280,-68 274,-68 268,-62 268,-56 268,-56 268,-12 268,-12 268,-6 274,0 280,0 280,0 369,0 369,0 375,0 381,-6 381,-12 381,-12 381,-56 381,-56 381,-62 375,-68 369,-68\"/>\n<text text-anchor=\"start\" x=\"287\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.497</text>\n<text text-anchor=\"start\" x=\"281\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 80</text>\n<text text-anchor=\"start\" x=\"276\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [37, 43]</text>\n<text text-anchor=\"start\" x=\"295.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n</g>\n<!-- 6&#45;&gt;10 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M283.08,-103.73C288.13,-95.34 293.47,-86.47 298.58,-78.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"301.48,-79.97 303.65,-69.6 295.49,-76.35 301.48,-79.97\"/>\n</g>\n<!-- 7 -->\n<g id=\"node10\" class=\"node\">\n<title>7</title>\n<path fill=\"#f5d0b5\" stroke=\"black\" d=\"M382,-298.5C382,-298.5 293,-298.5 293,-298.5 287,-298.5 281,-292.5 281,-286.5 281,-286.5 281,-242.5 281,-242.5 281,-236.5 287,-230.5 293,-230.5 293,-230.5 382,-230.5 382,-230.5 388,-230.5 394,-236.5 394,-242.5 394,-242.5 394,-286.5 394,-286.5 394,-292.5 388,-298.5 382,-298.5\"/>\n<text text-anchor=\"start\" x=\"300\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.473</text>\n<text text-anchor=\"start\" x=\"294\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"289\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 10]</text>\n<text text-anchor=\"start\" x=\"308.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;7 -->\n<g id=\"edge9\" class=\"edge\">\n<title>2&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M340.75,-341.58C340.32,-331.43 339.85,-320.5 339.41,-310.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"342.91,-310.21 338.99,-300.37 335.92,-310.51 342.91,-310.21\"/>\n</g>\n<!-- 8 -->\n<g id=\"node11\" class=\"node\">\n<title>8</title>\n<path fill=\"#6db7ec\" stroke=\"black\" d=\"M513,-298.5C513,-298.5 424,-298.5 424,-298.5 418,-298.5 412,-292.5 412,-286.5 412,-286.5 412,-242.5 412,-242.5 412,-236.5 418,-230.5 424,-230.5 424,-230.5 513,-230.5 513,-230.5 519,-230.5 525,-236.5 525,-242.5 525,-242.5 525,-286.5 525,-286.5 525,-292.5 519,-298.5 513,-298.5\"/>\n<text text-anchor=\"start\" x=\"431\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.331</text>\n<text text-anchor=\"start\" x=\"421\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 105</text>\n<text text-anchor=\"start\" x=\"420\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [22, 83]</text>\n<text text-anchor=\"start\" x=\"439.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge10\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M386.57,-341.58C398.79,-330.23 412.06,-317.9 424.3,-306.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"426.52,-309.26 431.46,-299.89 421.75,-304.13 426.52,-309.26\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x2099b1a6290>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#save the feature list into a vector (sono i nomi delle colonne del dataset)\n",
        "features=list(df.columns.values)\n",
        "\n",
        "import graphviz\n",
        "dot_data = tree.export_graphviz(tree_clf, out_file=None, \n",
        "                     feature_names=features[0:-1],  \n",
        "                     class_names=['0','1'],  \n",
        "                     filled=True, rounded=True,  \n",
        "                     special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render('diabetes')\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6POwDN-mETb"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1OFpmWp06gdcejF-I2-sSstTgHZvIhPe5\" width=\"500\" align=\"left\">\n",
        "\n",
        "Vediamo come si è mosso il metodo. Tra le variabili indipendenti, ha scelto di partire da _gluctol_ che aveva un indice di Gini di 0,454. Ha scelto il valore con cui effettuare il confronto (139.5) e ha suddiviso (split) i dati in due sottoinsiemi, quelli con _gluctol_ <= 139.5 (335 campioni) e gli altri (179 campioni). Dopodichè ha lavorato sui valori di un'altra variabile indipendente, _massindex_ ed è riuscito ad ottenere le prime tre foglie. A quel punto ha riutilizzzato nuovamente  _gluctol_ (perché tra tutte le variabili indipendenti era quella con l'indice di Gini più basso) ottenendo una nuova foglia e un sottoinsieme di cui ha analizzato l'età per ottenere le ultime due foglie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXbQvbubmETb"
      },
      "source": [
        "E' anche possibile vedere lo stesso albero in forma testuale:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_zzvtcsUmETc",
        "outputId": "c2d7077e-a104-4ae6-93cc-2c578f321c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|--- gluctol <= 139.50\n",
            "|   |--- massindex <= 27.35\n",
            "|   |   |--- class: 0.0\n",
            "|   |--- massindex >  27.35\n",
            "|   |   |--- gluctol <= 103.50\n",
            "|   |   |   |--- class: 0.0\n",
            "|   |   |--- gluctol >  103.50\n",
            "|   |   |   |--- age <= 28.50\n",
            "|   |   |   |   |--- class: 0.0\n",
            "|   |   |   |--- age >  28.50\n",
            "|   |   |   |   |--- class: 1.0\n",
            "|--- gluctol >  139.50\n",
            "|   |--- massindex <= 29.85\n",
            "|   |   |--- class: 0.0\n",
            "|   |--- massindex >  29.85\n",
            "|   |   |--- class: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import export_text\n",
        "r = export_text(tree_clf, feature_names=features[0:-1])\n",
        "print(r)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
